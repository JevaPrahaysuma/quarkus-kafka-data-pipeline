ğŸ“Œ Data Pipeline Project
ğŸ“– Overview

This project is a simple data pipeline built with Quarkus, PostgreSQL, and Apache Kafka.
It demonstrates how incoming messages from Kafka are processed, persisted into the database, and exposed via a REST API.

The project follows a modular clean structure:

Consumer â†’ Listens to Kafka topic

Service â†’ Processes messages

Repository â†’ Handles persistence

Controller â†’ REST API for accessing data

ğŸ—ï¸ System Design
Architecture Diagram
flowchart LR
    Kafka[(Kafka Topic)]
    Consumer[KafkaConsumerService]
    Service[DataProcessingService]
    Repo[DataRepository]
    DB[(PostgreSQL Database)]
    API[DataController]

    Kafka --> Consumer --> Service --> Repo --> DB
    API --> Repo

ğŸ”„ Sequence Diagram
sequenceDiagram
    participant P as Producer (Kafka)
    participant C as KafkaConsumerService
    participant S as DataProcessingService
    participant R as DataRepository
    participant DB as PostgreSQL
    participant API as DataController

    P->>C: Publish message
    C->>S: consume(message)
    S->>R: processAndSave(message)
    R->>DB: INSERT DataEntity
    API->>R: GET /data
    R->>API: return List<DataEntity>

ğŸ“‚ Project Structure
quarkus-kafka-data-pipeline/
 â”£ src/main/java/com/example/pipeline/
 â”ƒ â”£ controller/       # REST API Layer
 â”ƒ â”£ consumer/         # Kafka Consumer
 â”ƒ â”£ model/            # JPA Entities
 â”ƒ â”£ repository/       # Panache Repository
 â”ƒ â”— service/          # Business Logic
 â”£ src/test/java/com/example/pipeline/
 â”ƒ â”— DataPipelineTest.java
 â”£ src/main/resources/
 â”ƒ â”— application.properties
 â”— README.md


âš¡ API Documentation
1. Get All Data

Endpoint: GET /data

Description: Retrieves all data from database.

Response Example:

```json
[
  {
    "id": 1,
    "name": "KafkaMessage",
    "value": 123456789
  }
]
```

2. Create Data

Endpoint: POST /data

Description: Creates a new DataEntity entry.

Request Example:

```json
{
  "name": "ManualEntry",
  "value": 42
}
```


Response Example:

```json
{
  "id": 2,
  "name": "ManualEntry",
  "value": 42
}
```

â–¶ï¸ Running the Project
1. Start PostgreSQL

Make sure PostgreSQL is running and configured in application.properties:

quarkus.datasource.db-kind=postgresql
quarkus.datasource.username=postgres
quarkus.datasource.password=postgres
quarkus.datasource.jdbc.url=jdbc:postgresql://localhost:5432/pipeline
quarkus.hibernate-orm.database.generation=update

2. Start Kafka (Local)

If using Dev Services (Quarkus), Kafka will run automatically in dev mode.
Or manually start Kafka/Zookeeper (e.g. via Docker).

3. Run Application
mvn quarkus:dev

4. Access API

Open: http://localhost:8080/data

âœ… Testing

Run unit tests:

mvn test

Example: DataPipelineTest.java

Saves a test message using DataProcessingService

Verifies it was persisted correctly in the database

ğŸš€ Features

Kafka consumer integrated with Quarkus Reactive Messaging

PostgreSQL persistence with Panache ORM

REST API for data access

Unit test with QuarkusTest

ğŸ“Œ Next Steps

Add integration test for Kafka consumer

Add docker-compose for easier local setup (Kafka + Postgres)

Implement error handling & retries